<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</title>
    <style>
        body {
            font-family: "Times New Roman", serif;
            font-size: 15px;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #E3F1FE; /* 背景颜色 */
        }
        .header {
            background-color: #229EBC;
            color: white;
            padding: 20px 50px; /* 设置页眉左右内边距 */
            text-align: center;
        }
        .container {
            background-color: white;
            margin: 10px auto;
            max-width: 950px;
            padding-bottom: 1px; /* 添加底部内边距 */
        }
        .author-info {
            font-size: 12px;
            text-align: center;
            line-height: 1.4;
        }
        .notes {
            font-size: 12px;
            text-align: center;
            line-height: 1.4;
        }
        .image-container {
            text-align: center;
            margin: 20px 0;
        }
        /* Add margin-bottom to paragraphs */
        .container p {
            margin-bottom: 20px;
            padding: 0 20px; /* Add padding to paragraphs */
        }
        .section {
            background-color: white; /* Left background color */
            border-left: 20px solid white; /* White border */
            border-right: 20px solid white; /* White border */
            margin-bottom: 40px; /* Add gap between sections */
            padding: 0 20px; /* Add padding to sections */
        }
        .section h2 {
            color: #229EBC; /* Header color */
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</h1>
        <div class="author-info">
            <p>
                Zhaochen Su<sup>1<sup>∗</sup></sup>, 
                Juntao Li<sup>1<sup>†</sup></sup>, 
                Jun Zhang<sup>1</sup>, 
                Tong Zhu<sup>1</sup>
            </p>
            <p>
                <strong>Xiaoye Qu<sup>2,3</sup></strong>, 
                <strong>Pan Zhou<sup>3</sup></strong>, 
                <strong>Bowen Yan<sup>4</sup></strong>, 
                <strong>Yu Cheng<sup>5</sup></strong>, 
                <strong>Min Zhang<sup>1</sup></strong>
            </p>
            <p>
                <sup>1</sup>Institute of Computer Science and Technology, Soochow University, China<br>
                <sup>2</sup>Shanghai AI Laboratory, <sup>3</sup>Huazhong University of Science and Technology<br>
                <sup>4</sup>Tsinghua University, <sup>5</sup>The Chinese University of Hong Kong
            </p>
        </div>
        <div class="notes">
            <p>
                <sup>∗</sup>Work was done during the internship at Shanghai AI lab.<br>
                <sup>†</sup>Juntao Li is the Corresponding Author.
            </p>
        </div>
    </div>

    <div class="container">
        <div class="section">
            <h2>Why probe into co-temporal events?</h2>
            <div class="image-container">
                <img src="data.png" alt="Description of the image" width="450">
            </div>
            <p>In real-world scenarios, the relationships between events are often very complex. Taking Elon Musk and Sam Altman as examples, Elon Musk served as the chairman of Tesla from 2004 to 2018 and worked at OpenAI from 2015 to 2019, illustrating how the same individual can have overlapping roles across different organizations. Meanwhile, Sam Altman has been with OpenAI since 2015, overlapping with Elon Musk's tenure there. This demonstrates that different individuals can also have overlapping tenures within the same organization. To enable models to effectively represent and reason about the real world, understanding the logical connections between co-temporal events becomes even more crucial.</p>
        </div>
    </div>
        
    <div class="container">
        <div class="section">
            <h2>Introduction</h2>
            <p>Recent advancements in LLMs like GPT-4 have shown impressive capabilities, but they struggle with temporal reasoning, a critical aspect for understanding real-world events. Current datasets, like TIMEQA and TEMPREASON, mainly focus on single or isolated events, lacking the complexity of concurrent events seen in real-life situations.</p>
        </div>
    </div>
        
    <div class="container">
        <div class="section">
            <h2>Co-Temporal QA (COTEMP-QA) Benchmark</h2>
            <p>COTEMP-QA is designed to fill the gap by providing a comprehensive dataset that evaluates LLMs on co-temporal scenarios. It includes four types of co-temporal relations:</p>
            <ul>
                <li><strong>Equal:</strong> Events occur simultaneously.</li>
                <li><strong>Overlap:</strong> Events partially coincide in time.</li>
                <li><strong>During:</strong> One event is entirely within the timeline of another.</li>
                <li><strong>Mix:</strong> A combination of the above types.</li>
            </ul>
        </div>
    </div>
       
    <div class="container">
        <div class="section">
            <h2>Dataset Construction</h2>
            <p>The dataset is constructed using temporal facts extracted from Wikidata. These facts are structured and categorized into co-temporal relations. The questions in the dataset are designed to test the model's ability to reason about these concurrent events.</p>
        </div>
    </div>

    <div class="container">
        <div class="section">
            <h2>Experiments and Results</h2>
            <p>The experiments reveal that even advanced models like GPT-4 perform significantly below human-level reasoning on COTEMP-QA tasks. The Chain-of-Thought (CoT) strategy, though beneficial in some contexts, does not consistently improve performance in co-temporal reasoning tasks.</p>
        </div>
    </div>
        
    <div class="container">
        <div class="section">
            <h2>Mathematical Reasoning Strategy</h2>
            <p>The study proposes a mathematical reasoning strategy (MR-COT) to enhance co-temporal reasoning. This approach showed a notable improvement over existing methods but still lagged behind human performance.</p>
        </div>
    </div>
        
    <div class="container">
        <div class="section">
            <h2>Conclusion</h2>
            <p>The paper concludes that there is a substantial need for further advancements in improving the co-temporal reasoning capabilities of LLMs. The
            </div>
    </div>
</body>
</html>



