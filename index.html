<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            font-size: 14px;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #E3F1FE; /* 背景颜色 */
        }
        .header {
            background-color: #229EBC;
            color: white;
            padding: 20px 50px; /* 设置页眉左右内边距 */
            text-align: center;
        }
        .container {
            padding: 20px 50px; /* 设置内容区域左右内边距 */
            background-color: white; /* 设置内容区域背景颜色 */
            margin: 0 auto; /* 居中内容 */
            max-width: 800px; /* 最大宽度 */
        }
        .author-info {
            font-size: 12px;
            text-align: center;
            line-height: 1.4;
        }
        .notes {
            font-size: 12px;
            text-align: center;
            line-height: 1.4;
        }
        .image-container {
            text-align: center;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</h1>
        <div class="author-info">
            <p>
                Zhaochen Su<sup>1<sup>∗</sup></sup>, 
                Juntao Li<sup>1<sup>†</sup></sup>, 
                Jun Zhang<sup>1</sup>, 
                Tong Zhu<sup>1</sup>
            </p>
            <p>
                <strong>Xiaoye Qu<sup>2,3</sup></strong>, 
                <strong>Pan Zhou<sup>3</sup></strong>, 
                <strong>Bowen Yan<sup>4</sup></strong>, 
                <strong>Yu Cheng<sup>5</sup></strong>, 
                <strong>Min Zhang<sup>1</sup></strong>
            </p>
            <p>
                <sup>1</sup>Institute of Computer Science and Technology, Soochow University, China<br>
                <sup>2</sup>Shanghai AI Laboratory, <sup>3</sup>Huazhong University of Science and Technology<br>
                <sup>4</sup>Tsinghua University, <sup>5</sup>The Chinese University of Hong Kong
            </p>
        </div>
        <div class="notes">
            <p>
                <sup>∗</sup>Work was done during the internship at Shanghai AI lab.<br>
                <sup>†</sup>Juntao Li is the Corresponding Author.
            </p>
        </div>
    </div>
    <div class="container">
        <h2>Abstract</h2>
        <p>The paper addresses the limitations of current Large Language Models (LLMs) in handling temporal reasoning, particularly focusing on concurrent events and intricate temporal interconnections. The authors introduce COTEMP-QA, a benchmark designed to evaluate co-temporal reasoning across four scenarios (Equal, Overlap, During, Mix) with 4,748 samples. Experiments show a significant gap between human-level reasoning and current LLMs, even with Chain of Thought (CoT) methodologies. The study highlights the importance of mathematical reasoning in handling co-temporal events and proposes a strategy to improve LLMs' performance in this area.</p>
        
        <div class="image-container">
            <img src="data.png" alt="Description of the image" width="600">
        </div>
        
        <h2>Introduction</h2>
        <p>Recent advancements in LLMs like GPT-4 have shown impressive capabilities, but they struggle with temporal reasoning, a critical aspect for understanding real-world events. Current datasets, like TIMEQA and TEMPREASON, mainly focus on single or isolated events, lacking the complexity of concurrent events seen in real-life situations.</p>
        <h2>Co-Temporal QA (COTEMP-QA) Benchmark</h2>
        <p>COTEMP-QA is designed to fill the gap by providing a comprehensive dataset that evaluates LLMs on co-temporal scenarios. It includes four types of co-temporal relations:</p>
        <ul>
            <li><strong>Equal:</strong> Events occur simultaneously.</li>
            <li><strong>Overlap:</strong> Events partially coincide in time.</li>
            <li><strong>During:</strong> One event is entirely within the timeline of another.</li>
            <li><strong>Mix:</strong> A combination of the above types.</li>
        </ul>
        <h2>Dataset Construction</h2>
        <p>The dataset is constructed using temporal facts extracted from Wikidata. These facts are structured and categorized into co-temporal relations. The questions in the dataset are designed to test the model's ability to reason about these concurrent events.</p>
        <h2>Experiments and Results</h2>
        <p>The experiments reveal that even advanced models like GPT-4 perform significantly below human-level reasoning on COTEMP-QA tasks. The Chain-of-Thought (CoT) strategy, though beneficial in some contexts, does not consistently improve performance in co-temporal reasoning tasks.</p>
        <h2>Mathematical Reasoning Strategy</h2>
        <p>The study proposes a mathematical reasoning strategy (MR-COT) to enhance co-temporal reasoning. This approach showed a notable improvement over existing methods but still lagged behind human performance.</p>
        <h2>Conclusion</h2>
        <p>The paper concludes that there is a substantial need for further advancements in improving the co-temporal reasoning capabilities of LLMs. The COTEMP-QA benchmark is a step towards evaluating and fostering such improvements.</p>
    </div>
</body>
</html>



