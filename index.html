<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }
        .header {
            background-color: #007BFF;
            color: white;
            padding: 20px 0;
            text-align: center;
        }
        .container {
            padding: 20px;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?</h1>
        <p>Zhaochen Su, Juntao Li, Jun Zhang, Tong Zhu, Xiaoye Qu, Pan Zhou, Bowen Yan, Yu Cheng, Min Zhang</p>
        <p>Soochow University, China; Shanghai AI Laboratory; Huazhong University of Science and Technology; Tsinghua University; The Chinese University of Hong Kong</p>
    </div>
    <div class="container">
        <h2>Abstract</h2>
        <p>The paper addresses the limitations of current Large Language Models (LLMs) in handling temporal reasoning, particularly focusing on concurrent events and intricate temporal interconnections. The authors introduce COTEMP-QA, a benchmark designed to evaluate co-temporal reasoning across four scenarios (Equal, Overlap, During, Mix) with 4,748 samples. Experiments show a significant gap between human-level reasoning and current LLMs, even with Chain of Thought (CoT) methodologies. The study highlights the importance of mathematical reasoning in handling co-temporal events and proposes a strategy to improve LLMs' performance in this area.</p>
        <h2>Introduction</h2>
        <p>Recent advancements in LLMs like GPT-4 have shown impressive capabilities, but they struggle with temporal reasoning, a critical aspect for understanding real-world events. Current datasets, like TIMEQA and TEMPREASON, mainly focus on single or isolated events, lacking the complexity of concurrent events seen in real-life situations.</p>
        <h2>Co-Temporal QA (COTEMP-QA) Benchmark</h2>
        <p>COTEMP-QA is designed to fill the gap by providing a comprehensive dataset that evaluates LLMs on co-temporal scenarios. It includes four types of co-temporal relations:</p>
        <ul>
            <li><strong>Equal:</strong> Events occur simultaneously.</li>
            <li><strong>Overlap:</strong> Events partially coincide in time.</li>
            <li><strong>During:</strong> One event is entirely within the timeline of another.</li>
            <li><strong>Mix:</strong> A combination of the above types.</li>
        </ul>
        <h2>Dataset Construction</h2>
        <p>The dataset is constructed using temporal facts extracted from Wikidata. These facts are structured and categorized into co-temporal relations. The questions in the dataset are designed to test the model's ability to reason about these concurrent events.</p>
        <h2>Experiments and Results</h2>
        <p>The experiments reveal that even advanced models like GPT-4 perform significantly below human-level reasoning on COTEMP-QA tasks. The Chain-of-Thought (CoT) strategy, though beneficial in some contexts, does not consistently improve performance in co-temporal reasoning tasks.</p>
        <h2>Mathematical Reasoning Strategy</h2>
        <p>The study proposes a mathematical reasoning strategy (MR-COT) to enhance co-temporal reasoning. This approach showed a notable improvement over existing methods but still lagged behind human performance.</p>
        <h2>Conclusion</h2>
        <p>The paper concludes that there is a substantial need for further advancements in improving the co-temporal reasoning capabilities of LLMs. The COTEMP-QA benchmark is a step towards evaluating and fostering such improvements.</p>
    </div>
</body>
</html>
